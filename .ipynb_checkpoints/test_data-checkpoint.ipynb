{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(\"/scratch/group/csce435-f23/python-3.8.17/lib/python3.8/site-packages\")\n",
    "sys.path.append(\"/scratch/group/csce435-f23/thicket\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import thicket as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POINT THIS AT YOUR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point this at the top directory of all your cali files for all of the implementations. Other files can be in the directory too, that is ok.\n",
    "FILES_LOCATION = \"cali_files/*.cali\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader check\n",
    "Can the files be read in one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_files = []\n",
    "error_files = []\n",
    "i = 0\n",
    "team_files = glob(f\"{FILES_LOCATION}/**/*.cali\", recursive=True)\n",
    "for file in team_files:\n",
    "    try:\n",
    "        tk = th.Thicket.from_caliperreader(file)\n",
    "        working_files.append(file)\n",
    "    except Exception:\n",
    "        i += 1\n",
    "        error_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files that could be read in individually (one-by-one):\")\n",
    "print(f\"{len(working_files)}/{len(team_files)} ({len(working_files)/len(team_files)*100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Metadata columns\n",
    "\n",
    "Check for the necessary metadata columns from the [report](https://github.com/TAMU-CSCE435-Pearce/Project/blob/master/Report.md#3b-collect-metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_metadata_valid = []\n",
    "metadata_columns=['cali.caliper.version', 'spot.options', 'spot.channels', 'cali.channel',\n",
    "    'launchdate',\n",
    "    'libraries', 'cmdline', 'cluster', 'Algorithm', 'ProgrammingModel',\n",
    "    'Datatype', 'SizeOfDatatype', 'InputSize', 'InputType',\n",
    "    'group_num', 'implementation_source']\n",
    "mpi_cols = ['num_procs']\n",
    "cuda_cols = ['num_threads', 'num_blocks',]\n",
    "metadata_col_dict = defaultdict(lambda: [])\n",
    "\n",
    "team_files = glob(f\"{FILES_LOCATION}/**/*.cali\", recursive=True)\n",
    "for file in team_files:\n",
    "    try:\n",
    "        valid = True\n",
    "        tk = th.Thicket.from_caliperreader(file)\n",
    "        cols = tk.metadata.columns\n",
    "        model_to_check = []\n",
    "        if \"CUDA\" in tk.metadata[\"ProgrammingModel\"].to_list()[0].upper():\n",
    "            model_to_check = metadata_columns + cuda_cols\n",
    "        else:\n",
    "            model_to_check = metadata_columns + mpi_cols\n",
    "        for col in model_to_check:\n",
    "            if col not in cols:\n",
    "                metadata_col_dict[list(tk.profile_mapping.values())[0]].append(col)\n",
    "                valid=False\n",
    "        if valid:\n",
    "            team_metadata_valid.append(file)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "for file, cols in metadata_col_dict.items():\n",
    "    print(f\"File '{file}' missing metadata columns:\\n\\t{cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for DataFrame columns\n",
    "\n",
    "Check for the necessary DataFrame columns from the [report](https://github.com/TAMU-CSCE435-Pearce/Project/blob/master/Report.md#4c-you-should-measure-the-following-performance-metrics). For the GPU columns, you need one or the other column in the tuple, not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dataframe_valid = []\n",
    "necessary_columns = [\"Min time/rank\",\"Max time/rank\",\"Avg time/rank\",\"Total time\",]\n",
    "not_gpu_columns = [\"Variance time/rank\",]\n",
    "gpu_columns=[(\"Avg GPU time/rank\", \"Avg GPU Time/rank\"),\n",
    "             (\"Min GPU time/rank\", \"Min GPU Time/rank\"),\n",
    "             (\"Max GPU time/rank\", \"Max GPU Time/rank\"),\n",
    "             (\"Total GPU time\", \"Total GPU Time\"),]\n",
    "def check_df_cols(tk, dict):\n",
    "    valid = True\n",
    "    cols = tk.dataframe.columns\n",
    "    for col in necessary_columns:\n",
    "        if col not in cols:\n",
    "            dict[list(tk.profile_mapping.values())[0]].append(col)\n",
    "            valid = False\n",
    "    if \"ProgrammingModel\" in tk.metadata.columns:\n",
    "        if \"CUDA\" in tk.metadata[\"ProgrammingModel\"].to_list()[0].upper():\n",
    "            for col in gpu_columns:\n",
    "                if col[0] not in cols and col[1] not in cols:\n",
    "                    dict[list(tk.profile_mapping.values())[0]].append(col)\n",
    "                    valid = False\n",
    "        else:\n",
    "            for col in not_gpu_columns:\n",
    "                if col not in cols:\n",
    "                    dict[list(tk.profile_mapping.values())[0]].append(col)\n",
    "                    valid = False\n",
    "    return valid\n",
    "\n",
    "dataframe_col_dict = defaultdict(lambda: [])\n",
    "team_files = glob(f\"{FILES_LOCATION}/**/*.cali\", recursive=True)\n",
    "for file in team_files:\n",
    "    tk = th.Thicket.from_caliperreader(file)\n",
    "    valid = check_df_cols(tk, dataframe_col_dict)\n",
    "    if valid:\n",
    "        team_dataframe_valid.append(file)\n",
    "\n",
    "for file, cols in dataframe_col_dict.items():\n",
    "    print(f\"File '{file}' missing dataframe columns: {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try all files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = th.Thicket.from_caliperreader(team_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check tree\n",
    "\n",
    "Should be no different from the [report](https://github.com/TAMU-CSCE435-Pearce/Project/blob/master/Report.md#3a-caliper-instrumentation), spelling and all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk.statsframe.dataframe[\"time\"] = 1\n",
    "print(tk.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby programming model. Should result in 2 thickets, MPI and CUDA.\n",
    "gb_pmodel = tk.groupby(\"ProgrammingModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby the parameters we ran with. After this operation, each Thicket in gb_total should contain profiles with unique InputSizes (there should be no duplicate input sizes).\n",
    "gb_cuda = gb_pmodel[\"CUDA\"].groupby([\"ProgrammingModel\", \"Algorithm\", \"InputType\", \"num_threads\"])\n",
    "gb_mpi = gb_pmodel[\"MPI\"].groupby([\"ProgrammingModel\", \"Algorithm\", \"InputType\", \"num_procs\"])\n",
    "gb_total = {**gb_cuda, **gb_mpi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose all of the data back together. If this step errors, you probably have duplicate inputsizes. Run 1a to check for this.\n",
    "ctk = th.Thicket.concat_thickets(\n",
    "    thickets=list(gb_total.values()),\n",
    "    axis=\"columns\",\n",
    "    headers=list(gb_total.keys()),\n",
    "    metadata_key=\"InputSize\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctk.dataframe.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1A\n",
    "\n",
    "Check for duplicate input sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key in list(gb_total.keys()):\n",
    "    print(i)\n",
    "    print(gb_total[key].profile_mapping)\n",
    "    print(gb_total[key].metadata[\"InputSize\"])\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
